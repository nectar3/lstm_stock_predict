{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing GRU and LSTM with Stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ample\\miniconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "#!pip install yfinance\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "# numpy 설치했음에도 에러가 날때\n",
    "sys.path.append('C:\\\\Users\\\\ample\\\\miniconda3\\\\envs\\\\tensorflow\\\\lib\\\\site-packages')\n",
    "sys.path.append('C:\\\\Users\\\\ample\\\\miniconda3\\\\envs\\\\tensorflow')\n",
    "sys.path.append('C:\\\\Users\\\\ample\\\\miniconda3\\\\envs\\\\tensorflow\\\\lib')       \n",
    "sys.path.append('C:\\\\Users\\\\ample\\\\miniconda3\\\\envs\\\\tensorflow\\\\DLLs')        \n",
    "sys.path.append('C:\\\\Users\\\\ample\\\\miniconda3\\\\envs\\\\tensorflow\\\\python37.zip')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id    code  name        date  endprice  updown  compare  volume  \\\n",
      "0   0  041140  넥슨지티  2018-12-17      6670       0        0  107077   \n",
      "1   0  041140  넥슨지티  2018-12-18      6400       0        0  221561   \n",
      "2   0  041140  넥슨지티  2018-12-19      6420       0        0   71970   \n",
      "3   0  041140  넥슨지티  2018-12-20      6200       0        0  169073   \n",
      "4   0  041140  넥슨지티  2018-12-21      6570       0        0  219149   \n",
      "\n",
      "   totalmoney  startprice  highprice  lowprice  mkcap  shares  ratio_start  \\\n",
      "0   717829310        6720       6800      6650      0       0        -0.74   \n",
      "1  1432389880        6590       6610      6380      0       0        -1.20   \n",
      "2   461318390        6360       6480      6350      0       0        -0.63   \n",
      "3  1050639810        6350       6400      6120      0       0        -1.09   \n",
      "4  1406672180        6150       6650      6150      0       0        -0.81   \n",
      "\n",
      "   ratio_high  ratio_low  ratio_end  \n",
      "0        0.44      -1.77      -1.48  \n",
      "1       -0.90      -4.35      -4.05  \n",
      "2        1.25      -0.78       0.31  \n",
      "3       -0.31      -4.67      -3.43  \n",
      "4        7.26      -0.81       5.97  \n",
      "(42755, 18)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"D:\\\\Dev\\\\CSharp\\\\DBmakerForDeeplearn\\\\DBmakerForDeeplearn\\\\bin\\\\Debug\\\\DB\\\\GijoonForKeras.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT * FROM gijoon\") \n",
    "             \n",
    "rows = cur.fetchall()\n",
    "\n",
    "df = pd.DataFrame(rows, columns=['id', 'code', 'name', 'date', 'endprice', 'updown', 'compare', 'volume', 'totalmoney', 'startprice', 'highprice', 'lowprice', 'mkcap', 'shares', 'ratio_start', 'ratio_high', 'ratio_low', 'ratio_end'])\n",
    "\n",
    "print(df[0:5])\n",
    "print(df.shape)\n",
    "    \n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42755, 6)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   id         0         1         2         3         4\n",
      "0   0 -0.024504  0.014667 -0.058843 -0.049333 -0.999676\n",
      "1   0 -0.039840 -0.030000 -0.144857 -0.135000 -0.999331\n",
      "2   0 -0.020837  0.041667 -0.025838  0.010333 -0.999800\n",
      "3   0 -0.036173 -0.010333 -0.155526 -0.114333 -0.999515\n",
      "4   0 -0.026838  0.242000 -0.026838  0.199000 -0.999344\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "all_data = df[['id', 'ratio_start', 'ratio_high', 'ratio_low', 'ratio_end', 'totalmoney']]\n",
    "\n",
    "FEATURES = all_data.shape[1] - 1 # id 열 제외할거기 때문에 1 빼줌\n",
    "\n",
    "all_data['ratio_end'].plot()\n",
    "\n",
    "print(all_data.shape)\n",
    "print(type(all_data)) # 'pandas.core.frame.DataFrame'\n",
    "\n",
    "\n",
    "# 스케일러 하나 만들어두고 전 데이터 fit\n",
    "sc = MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "# id열 뗀 나머지 스케일 하고 다시 id 붙이기\n",
    "for_scale = all_data.iloc[:,1:]\n",
    "scaled = sc.fit_transform(for_scale)  # 전 데이터로 fit\n",
    "id = all_data.iloc[:,0]\n",
    "scaled = pd.DataFrame(scaled)\n",
    "\n",
    "all_scaled = pd.concat([id,scaled],axis=1)\n",
    "print(all_scaled[0:5])\n",
    "print(type(all_scaled))\n",
    "\n",
    "\n",
    "#def ScaleAndReAttachID(dataList):\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ratio_start</th>\n",
       "      <th>ratio_high</th>\n",
       "      <th>ratio_low</th>\n",
       "      <th>ratio_end</th>\n",
       "      <th>totalmoney</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.44</td>\n",
       "      <td>-1.77</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>717829310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-4.35</td>\n",
       "      <td>-4.05</td>\n",
       "      <td>1432389880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>0.31</td>\n",
       "      <td>461318390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-4.67</td>\n",
       "      <td>-3.43</td>\n",
       "      <td>1050639810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>7.26</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>5.97</td>\n",
       "      <td>1406672180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>3.35</td>\n",
       "      <td>-2.44</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1383244450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.18</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-4.69</td>\n",
       "      <td>-3.93</td>\n",
       "      <td>816762500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.89</td>\n",
       "      <td>726211170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1.08</td>\n",
       "      <td>422341330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.83</td>\n",
       "      <td>-3.06</td>\n",
       "      <td>-2.60</td>\n",
       "      <td>549846500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>11.46</td>\n",
       "      <td>29.98</td>\n",
       "      <td>11.30</td>\n",
       "      <td>29.98</td>\n",
       "      <td>18291898970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>14.73</td>\n",
       "      <td>26.21</td>\n",
       "      <td>12.44</td>\n",
       "      <td>18.00</td>\n",
       "      <td>122610235750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>11.57</td>\n",
       "      <td>29.99</td>\n",
       "      <td>9.52</td>\n",
       "      <td>29.99</td>\n",
       "      <td>137312312090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>6.30</td>\n",
       "      <td>-3.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>88388177950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-5.91</td>\n",
       "      <td>-3.54</td>\n",
       "      <td>38190594100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  ratio_start  ratio_high  ratio_low  ratio_end    totalmoney\n",
       "0    0        -0.74        0.44      -1.77      -1.48     717829310\n",
       "1    0        -1.20       -0.90      -4.35      -4.05    1432389880\n",
       "2    0        -0.63        1.25      -0.78       0.31     461318390\n",
       "3    0        -1.09       -0.31      -4.67      -3.43    1050639810\n",
       "4    0        -0.81        7.26      -0.81       5.97    1406672180\n",
       "5    0        -1.37        3.35      -2.44       0.61    1383244450\n",
       "6    0        -3.18       -1.36      -4.69      -3.93     816762500\n",
       "7    0         0.94        6.30       0.79       1.89     726211170\n",
       "8    0         0.77        2.78       0.62       1.08     422341330\n",
       "9    0         1.83        1.83      -3.06      -2.60     549846500\n",
       "10   0        11.46       29.98      11.30      29.98   18291898970\n",
       "11   0        14.73       26.21      12.44      18.00  122610235750\n",
       "12   0        11.57       29.99       9.52      29.99  137312312090\n",
       "13   0         0.39        6.30      -3.94       0.00   88388177950\n",
       "14   0        -1.18        0.79      -5.91      -3.54   38190594100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 7\n",
    "FOR_PERIODS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ample\\miniconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:106: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def Make_LSTM_model():\n",
    "    # create a model. LSTM architecture\n",
    "    my_LSTM_model = Sequential()\n",
    "    my_LSTM_model.add(LSTM(units = 50, \n",
    "                           return_sequences = True, \n",
    "                           input_shape = (TIME_STEPS, FEATURES),  # (timestep, feature)\n",
    "                           activation = 'tanh'))\n",
    "    my_LSTM_model.add(LSTM(units = 50, activation = 'tanh'))\n",
    "    my_LSTM_model.add(Dense(units=5))\n",
    "    \n",
    "    # Compiling \n",
    "    my_LSTM_model.compile(optimizer = SGD(lr = 0.01, decay = 1e-7, \n",
    "                                         momentum = 0.9, nesterov = False),\n",
    "                         loss = 'mean_squared_error')\n",
    "    return my_LSTM_model \n",
    "\n",
    "my_LSTM_model = Make_LSTM_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모듈로 구분하기, scale / train \n",
    "# 학습, 테스트 데이터 구분하기\n",
    "\n",
    "# 부분 시퀀스로 나눔\n",
    "def PrepareData(data, time_steps, for_periods):\n",
    "    # 몇종목은 학습 데이터로, 나머지 종목은 테스트 데이터로\n",
    "    \n",
    "    dataLen = len(data)\n",
    "    # create training data of s samples and t time steps \n",
    "    X_train = [] \n",
    "    y_train = [] \n",
    "    for i in range(time_steps, dataLen-1):  # 종가를 타임스텝5로 잘라 배열하는듯. range(n, m) n 부터 m까지\n",
    "        X_train.append(data[i-time_steps:i]) # 종가 5개\n",
    "        y_train.append(data[i:i+for_periods]) # 결과 for_periods개 \n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    #X_train_3d = X_train.reshape(X_train.shape[0], time_steps, FEATURES)\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def MakeDataAndFitModel(jongData):\n",
    "\n",
    "    X_train, y_train = PrepareData(jongData, TIME_STEPS, FOR_PERIODS)\n",
    "    print(X_train.shape)\n",
    "     \n",
    "    # Fitting to the training set \n",
    "    my_LSTM_model.fit(X_train, y_train, epochs = 50, batch_size = 150, verbose = 0)\n",
    "    \n",
    "    # print(X_train[0:5])\n",
    "    # 원래 예제 다시보기 feature가 1개다. 내 경우는 5개로 조정\n",
    "    #print('X_train.shape: ' + \", \".join(map(str,X_train.shape))) # (210, 7, 5) # 데이터, 시퀀스 길이, 피쳐\n",
    "    #print('y_train.shape: ' + \", \".join(map(str,y_train.shape))) # (210, 1, 5)\n",
    "    \n",
    "def GetDataByIndex(index):\n",
    "    return all_scaled[all_scaled['id'] == index].iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(43, 7, 5)\n",
      "1\n",
      "(44, 7, 5)\n",
      "2\n",
      "(46, 7, 5)\n",
      "3\n",
      "(48, 7, 5)\n",
      "4\n",
      "(47, 7, 5)\n",
      "5\n",
      "(49, 7, 5)\n",
      "6\n",
      "(47, 7, 5)\n",
      "7\n",
      "(46, 7, 5)\n",
      "8\n",
      "(47, 7, 5)\n",
      "9\n",
      "(46, 7, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10):  # range(n) [0...n-1]\n",
    "    print(i)\n",
    "    part = GetDataByIndex(i)\n",
    "    MakeDataAndFitModel(part)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0         1         2         3         4\n",
      "0  -0.024504  0.014667 -0.058843 -0.049333 -0.999676\n",
      "1  -0.039840 -0.030000 -0.144857 -0.135000 -0.999331\n",
      "2  -0.020837  0.041667 -0.025838  0.010333 -0.999800\n",
      "3  -0.036173 -0.010333 -0.155526 -0.114333 -0.999515\n",
      "4  -0.026838  0.242000 -0.026838  0.199000 -0.999344\n",
      "5  -0.045508  0.111667 -0.081180  0.020333 -0.999355\n",
      "6  -0.105851 -0.045333 -0.156193 -0.131000 -0.999628\n",
      "7   0.031505  0.210000  0.026504  0.063000 -0.999672\n",
      "8   0.025838  0.092667  0.020837  0.036000 -0.999818\n",
      "9   0.061177  0.061000 -0.101850 -0.086667 -0.999757\n",
      "10  0.382230  0.999333  0.376896  0.999333 -0.991197\n",
      "11  0.491249  0.873667  0.414902  0.600000 -0.940870\n",
      "12  0.385898  0.999667  0.317553  0.999667 -0.933777\n",
      "13  0.013169  0.210000 -0.131189  0.000000 -0.957380\n",
      "14 -0.039173  0.026333 -0.196866 -0.118000 -0.981597\n",
      "------\n",
      "[[[-0.02450408  0.01466667 -0.05884314 -0.04933333 -0.9996759 ]\n",
      "  [-0.03983997 -0.03       -0.14485748 -0.135      -0.99933116]\n",
      "  [-0.02083681  0.04166667 -0.02583764  0.01033333 -0.99979965]\n",
      "  [-0.0361727  -0.01033333 -0.15552592 -0.11433333 -0.99951533]\n",
      "  [-0.02683781  0.242      -0.02683781  0.199      -0.99934357]\n",
      "  [-0.04550758  0.11166667 -0.0811802   0.02033333 -0.99935487]\n",
      "  [-0.10585098 -0.04533333 -0.1561927  -0.131      -0.99962817]]\n",
      "\n",
      " [[-0.03983997 -0.03       -0.14485748 -0.135      -0.99933116]\n",
      "  [-0.02083681  0.04166667 -0.02583764  0.01033333 -0.99979965]\n",
      "  [-0.0361727  -0.01033333 -0.15552592 -0.11433333 -0.99951533]\n",
      "  [-0.02683781  0.242      -0.02683781  0.199      -0.99934357]\n",
      "  [-0.04550758  0.11166667 -0.0811802   0.02033333 -0.99935487]\n",
      "  [-0.10585098 -0.04533333 -0.1561927  -0.131      -0.99962817]\n",
      "  [ 0.03150525  0.21        0.02650442  0.063      -0.99967185]]\n",
      "\n",
      " [[-0.02083681  0.04166667 -0.02583764  0.01033333 -0.99979965]\n",
      "  [-0.0361727  -0.01033333 -0.15552592 -0.11433333 -0.99951533]\n",
      "  [-0.02683781  0.242      -0.02683781  0.199      -0.99934357]\n",
      "  [-0.04550758  0.11166667 -0.0811802   0.02033333 -0.99935487]\n",
      "  [-0.10585098 -0.04533333 -0.1561927  -0.131      -0.99962817]\n",
      "  [ 0.03150525  0.21        0.02650442  0.063      -0.99967185]\n",
      "  [ 0.02583764  0.09266667  0.02083681  0.036      -0.99981845]]\n",
      "\n",
      " [[-0.0361727  -0.01033333 -0.15552592 -0.11433333 -0.99951533]\n",
      "  [-0.02683781  0.242      -0.02683781  0.199      -0.99934357]\n",
      "  [-0.04550758  0.11166667 -0.0811802   0.02033333 -0.99935487]\n",
      "  [-0.10585098 -0.04533333 -0.1561927  -0.131      -0.99962817]\n",
      "  [ 0.03150525  0.21        0.02650442  0.063      -0.99967185]\n",
      "  [ 0.02583764  0.09266667  0.02083681  0.036      -0.99981845]\n",
      "  [ 0.06117686  0.061      -0.10185031 -0.08666667 -0.99975694]]\n",
      "\n",
      " [[-0.02683781  0.242      -0.02683781  0.199      -0.99934357]\n",
      "  [-0.04550758  0.11166667 -0.0811802   0.02033333 -0.99935487]\n",
      "  [-0.10585098 -0.04533333 -0.1561927  -0.131      -0.99962817]\n",
      "  [ 0.03150525  0.21        0.02650442  0.063      -0.99967185]\n",
      "  [ 0.02583764  0.09266667  0.02083681  0.036      -0.99981845]\n",
      "  [ 0.06117686  0.061      -0.10185031 -0.08666667 -0.99975694]\n",
      "  [ 0.38223037  0.99933333  0.37689615  0.99933333 -0.99119739]]\n",
      "\n",
      " [[-0.04550758  0.11166667 -0.0811802   0.02033333 -0.99935487]\n",
      "  [-0.10585098 -0.04533333 -0.1561927  -0.131      -0.99962817]\n",
      "  [ 0.03150525  0.21        0.02650442  0.063      -0.99967185]\n",
      "  [ 0.02583764  0.09266667  0.02083681  0.036      -0.99981845]\n",
      "  [ 0.06117686  0.061      -0.10185031 -0.08666667 -0.99975694]\n",
      "  [ 0.38223037  0.99933333  0.37689615  0.99933333 -0.99119739]\n",
      "  [ 0.49124854  0.87366667  0.41490248  0.6        -0.94086965]]\n",
      "\n",
      " [[-0.10585098 -0.04533333 -0.1561927  -0.131      -0.99962817]\n",
      "  [ 0.03150525  0.21        0.02650442  0.063      -0.99967185]\n",
      "  [ 0.02583764  0.09266667  0.02083681  0.036      -0.99981845]\n",
      "  [ 0.06117686  0.061      -0.10185031 -0.08666667 -0.99975694]\n",
      "  [ 0.38223037  0.99933333  0.37689615  0.99933333 -0.99119739]\n",
      "  [ 0.49124854  0.87366667  0.41490248  0.6        -0.94086965]\n",
      "  [ 0.38589765  0.99966667  0.31755293  0.99966667 -0.93377672]]\n",
      "\n",
      " [[ 0.03150525  0.21        0.02650442  0.063      -0.99967185]\n",
      "  [ 0.02583764  0.09266667  0.02083681  0.036      -0.99981845]\n",
      "  [ 0.06117686  0.061      -0.10185031 -0.08666667 -0.99975694]\n",
      "  [ 0.38223037  0.99933333  0.37689615  0.99933333 -0.99119739]\n",
      "  [ 0.49124854  0.87366667  0.41490248  0.6        -0.94086965]\n",
      "  [ 0.38589765  0.99966667  0.31755293  0.99966667 -0.93377672]\n",
      "  [ 0.01316886  0.21       -0.13118853  0.         -0.95737987]]\n",
      "\n",
      " [[ 0.02583764  0.09266667  0.02083681  0.036      -0.99981845]\n",
      "  [ 0.06117686  0.061      -0.10185031 -0.08666667 -0.99975694]\n",
      "  [ 0.38223037  0.99933333  0.37689615  0.99933333 -0.99119739]\n",
      "  [ 0.49124854  0.87366667  0.41490248  0.6        -0.94086965]\n",
      "  [ 0.38589765  0.99966667  0.31755293  0.99966667 -0.93377672]\n",
      "  [ 0.01316886  0.21       -0.13118853  0.         -0.95737987]\n",
      "  [-0.0391732   0.02633333 -0.19686614 -0.118      -0.98159739]]\n",
      "\n",
      " [[ 0.06117686  0.061      -0.10185031 -0.08666667 -0.99975694]\n",
      "  [ 0.38223037  0.99933333  0.37689615  0.99933333 -0.99119739]\n",
      "  [ 0.49124854  0.87366667  0.41490248  0.6        -0.94086965]\n",
      "  [ 0.38589765  0.99966667  0.31755293  0.99966667 -0.93377672]\n",
      "  [ 0.01316886  0.21       -0.13118853  0.         -0.95737987]\n",
      "  [-0.0391732   0.02633333 -0.19686614 -0.118      -0.98159739]\n",
      "  [-0.12218703 -0.05433333 -0.25854309 -0.08166667 -0.97996325]]\n",
      "\n",
      " [[ 0.38223037  0.99933333  0.37689615  0.99933333 -0.99119739]\n",
      "  [ 0.49124854  0.87366667  0.41490248  0.6        -0.94086965]\n",
      "  [ 0.38589765  0.99966667  0.31755293  0.99966667 -0.93377672]\n",
      "  [ 0.01316886  0.21       -0.13118853  0.         -0.95737987]\n",
      "  [-0.0391732   0.02633333 -0.19686614 -0.118      -0.98159739]\n",
      "  [-0.12218703 -0.05433333 -0.25854309 -0.08166667 -0.97996325]\n",
      "  [-0.06951159  0.028      -0.29288215 -0.293      -0.98462153]]\n",
      "\n",
      " [[ 0.49124854  0.87366667  0.41490248  0.6        -0.94086965]\n",
      "  [ 0.38589765  0.99966667  0.31755293  0.99966667 -0.93377672]\n",
      "  [ 0.01316886  0.21       -0.13118853  0.         -0.95737987]\n",
      "  [-0.0391732   0.02633333 -0.19686614 -0.118      -0.98159739]\n",
      "  [-0.12218703 -0.05433333 -0.25854309 -0.08166667 -0.97996325]\n",
      "  [-0.06951159  0.028      -0.29288215 -0.293      -0.98462153]\n",
      "  [-0.03050508  0.09166667 -0.07617936  0.         -0.9884994 ]]\n",
      "\n",
      " [[ 0.38589765  0.99966667  0.31755293  0.99966667 -0.93377672]\n",
      "  [ 0.01316886  0.21       -0.13118853  0.         -0.95737987]\n",
      "  [-0.0391732   0.02633333 -0.19686614 -0.118      -0.98159739]\n",
      "  [-0.12218703 -0.05433333 -0.25854309 -0.08166667 -0.97996325]\n",
      "  [-0.06951159  0.028      -0.29288215 -0.293      -0.98462153]\n",
      "  [-0.03050508  0.09166667 -0.07617936  0.         -0.9884994 ]\n",
      "  [ 0.04617436  0.96333333  0.01550258  0.795      -0.90018225]]\n",
      "\n",
      " [[ 0.01316886  0.21       -0.13118853  0.         -0.95737987]\n",
      "  [-0.0391732   0.02633333 -0.19686614 -0.118      -0.98159739]\n",
      "  [-0.12218703 -0.05433333 -0.25854309 -0.08166667 -0.97996325]\n",
      "  [-0.06951159  0.028      -0.29288215 -0.293      -0.98462153]\n",
      "  [-0.03050508  0.09166667 -0.07617936  0.         -0.9884994 ]\n",
      "  [ 0.04617436  0.96333333  0.01550258  0.795      -0.90018225]\n",
      "  [-0.08618103 -0.08633333 -0.2222037  -0.18533333 -0.9927318 ]]\n",
      "\n",
      " [[-0.0391732   0.02633333 -0.19686614 -0.118      -0.98159739]\n",
      "  [-0.12218703 -0.05433333 -0.25854309 -0.08166667 -0.97996325]\n",
      "  [-0.06951159  0.028      -0.29288215 -0.293      -0.98462153]\n",
      "  [-0.03050508  0.09166667 -0.07617936  0.         -0.9884994 ]\n",
      "  [ 0.04617436  0.96333333  0.01550258  0.795      -0.90018225]\n",
      "  [-0.08618103 -0.08633333 -0.2222037  -0.18533333 -0.9927318 ]\n",
      "  [-0.0391732   0.03933333 -0.09151525 -0.013      -0.9944265 ]]]\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "=================\n",
      "LSTM_prediction: 43, 5\n",
      "[0.91 5.28 -2.18 1.12 49675358208.00]\n",
      "[0.90 5.31 -2.21 1.08 49578373120.00]\n",
      "[0.87 5.32 -2.26 1.09 51344728064.00]\n",
      "[0.86 5.31 -2.24 1.07 51121725440.00]\n",
      "[0.93 5.48 -2.32 1.04 66473222144.00]\n",
      "[0.99 5.57 -2.30 1.06 92973137920.00]\n",
      "[1.02 5.63 -2.44 1.12 115509641216.00]\n",
      "[0.92 5.48 -2.56 1.16 112295051264.00]\n",
      "[0.84 5.32 -2.64 1.16 93603594240.00]\n",
      "[0.76 5.16 -2.75 1.10 67093676032.00]\n",
      "[0.68 5.03 -2.82 1.01 40292065280.00]\n",
      "[0.75 5.08 -2.58 0.90 32373420032.00]\n",
      "[0.81 5.33 -2.55 0.77 40243634176.00]\n",
      "[0.80 5.41 -2.36 0.79 48562814976.00]\n",
      "[0.79 5.40 -2.40 0.85 48774946816.00]\n"
     ]
    }
   ],
   "source": [
    "orig = GetDataByIndex(0)\n",
    "X_test ,_= PrepareData(orig, TIME_STEPS, FOR_PERIODS)\n",
    "\n",
    "print(orig[0:15])\n",
    "print(\"------\")\n",
    "print(X_test[0:15])\n",
    "\n",
    "\n",
    "LSTM_prediction = my_LSTM_model.predict(X_test)\n",
    "\n",
    "LSTM_prediction = sc.inverse_transform(LSTM_prediction)\n",
    "\n",
    "print('=================')\n",
    "print('LSTM_prediction: ' + \", \".join(map(str,LSTM_prediction.shape)))\n",
    "#print(LSTM_prediction[0:30]) \n",
    "\n",
    "np.set_printoptions(formatter={'float_kind': lambda x: \"{0:0.2f}\".format(x)})\n",
    "result = np.round(LSTM_prediction, 2)\n",
    "\n",
    "dd = result[0:15]\n",
    "\n",
    "for data in dd:\n",
    "    print(data)\n",
    "    #print(\"{0:0.2f}\".format(cell))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n",
    "\n",
    "def confirm_result(y_test, y_pred):\n",
    "    MAE = mean_absolute_error(y_test, y_pred)\n",
    "    RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    MSLE = mean_squared_log_error(y_test, y_pred)\n",
    "    RMSLE = np.sqrt(mean_squared_log_error(y_test, y_pred))\n",
    "    R2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    pd.options.display.float_format = '{:.5f}'.format\n",
    "    Result = pd.DataFrame(data=[MAE,RMSE, RMSLE, R2],\n",
    "                         index = ['MAE','RMSE', 'RMSLE', 'R2'],\n",
    "                         columns=['Results'])\n",
    "    return Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>39.01289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>48.22952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSLE</th>\n",
       "      <td>0.02685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.77401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Results\n",
       "MAE   39.01289\n",
       "RMSE  48.22952\n",
       "RMSLE  0.02685\n",
       "R2     0.77401"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confirm_result(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
